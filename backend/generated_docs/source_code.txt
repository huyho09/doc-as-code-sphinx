
=== File: README.md ===

# openai-json

This is a project to test OpenAI API and NodeJS openAI framework

### Resolve Version Conflict

```
$env:OPENAI_API_KEY="secret key"
python==3.11
```

### How to run JS Source

1. Open the project folder in VSC
2. Use cli: 
```cd back-end```
3. Use cli: 
```npm i```
4. Use cli: 
```node server.js```
5. Start Live Server using **index.html** in front-end folder
6. Install [Allow CORS: Access-Control-Allow-Origin](https://chromewebstore.google.com/detail/allow-cors-access-control/lhobafahddgcelffkeicbaginigeejlf)

### How to run Python source with Anaconda (deprecated)
~~1. Create venv using conda: 
```conda env create -f environment.yml```
2. Using Cli: 
```python main.py```
3. Install [Allow CORS: Access-Control-Allow-Origin](https://chromewebstore.google.com/detail/allow-cors-access-control/lhobafahddgcelffkeicbaginigeejlf)
4. Start Live Server using **index.html** inside `openai-py` folder~~

### [UPDATE] How to run Python with .venv
1. Deactivate your running conda env: 
```conda deactivate <your_env_name>```
2. Remove conda env: 
```**conda env remove --name <your_env_name>```
3. Use cli: 
```cd openai-py```
4. Use cli to create virtual environment:
```
python -m venv <your_env_name>
# prefer using .venv because the venv is already in gitignore to avoid pushing the whole venv
python -m venv .venv
```
5. Activate venv by using cli:
```
.\.venv\Scripts\activate (Windows)
source .venv/bin/activate (MacOS)
```
6. Install all libs in requirements.txt
```
# On Windows
pip install -r requirements.txt
# On MacOS
python -m pip install -r requirements.txt
```
7. Deactivate .venv using `deactivate`

### Idea

The concept of this project is to build a dynamic chatbot using the OpenAI API. The user will input a question, and the chatbot will generate and respond with an answer based on pre-existing data stored in a `data.json` file. If the chatbot provides the correct answer (i.e., an answer found in the `data.json` file), the user can simply submit the response. However, if the chatbot’s response is incorrect or insufficient, the user has the ability to modify the answer in a provided text area.

In cases where the chatbot cannot find a suitable answer (i.e., the question is not present in the `data.json` file), it will return a generic response from OpenAI, indicating that the question is new. The user can then input their own answer, which will be appended to the `data.json` file, updating the dataset with new question-answer pairs for future reference. This ensures continuous learning and improvement of the chatbot over time.

The process flow involves the following steps:

1.  **User Inputs Question**: The user asks a question through the interface.
2.  **Chatbot Provides Answer**: The chatbot attempts to provide an answer based on the existing `data.json` file.
3.  **User Verifies or Edits Answer**: If the answer is correct, the user submits it as-is. If not, the user can modify the answer.
4.  **New Question Handling**: If the question is new (i.e., not in the existing dataset), the chatbot will respond with a general prompt from OpenAI. The user can then provide their own answer.
5.  **Data Update**: Any new answers, whether modified or provided by the user for a new question, will be appended to the `data.json` file.

This approach allows the chatbot to grow and adapt based on user input, enriching the dataset and improving the chatbot’s responses over time. The backend system will ensure that all updates to the `data.json` file are properly stored and can be referenced in future interactions, creating a personalized and continuously improving chatbot experience.

### Updates:
- Rework using Python OpenAI
- Using `gpt-3.5-turbo` instead of `davinci` to get more data responses

### To Do
- Restructure **json.data** to get the lastest update or random select the answer for one question.
- Implement Edit button to edit the response instead of using the popup.
- Implement [t5-base-e2e-qg](https://huggingface.co/valhalla/t5-base-e2e-qg).
- ~~Rework back-end using Python openAI framework~~

### Issues and Bugs:
- Website reload when chatbot responses

=== File: back-end-js/server.js ===
const express = require('express');
const cors = require('cors');
const bodyParser = require('body-parser');
const fs = require('fs');
const axios = require('axios');

const app = express();
app.use(cors()); // Alow CORS for all resource
app.use(bodyParser.json());

const apiKey = process.env.OPENAI_API_KEY;  

let data = require('./data.json'); // read json


app.post('/chat', async (req, res) => {
    const userQuestion = req.body.question;
    
    const found = data.questions.find(q => q.question.toLowerCase() === userQuestion.toLowerCase());

    if (found) {
        res.json({ answer: found.answer });
    } else {
        // Generate answer using OpenAI
        try {
            const response = await axios.post(
                'https://api.openai.com/v1/engines/text-davinci-003/completions',
                {
                    prompt: userQuestion,
                    max_tokens: 100,
                },
                {
                    headers: {
                        'Authorization': `Bearer ${apiKey}`,
                        'Content-Type': 'application/json',
                    },
                }
            );

            res.json({ answer: response.data.choices[0].text.trim() });
        } catch (error) {
            console.error('Error generating answer:', error);
            res.status(500).json({ error: 'Error generating answer' });
        }
    }
});

app.post('/verify', (req, res) => {
    const { question, answer, correct } = req.body;

    if (!correct) {
        data.questions.push({ question, answer });
        fs.writeFileSync('./data.json', JSON.stringify(data, null, 2));
    }

    res.sendStatus(200);
});

app.listen(3000, () => {
    console.log('Server running on port 3000');
});

=== File: openai-py/front-end/script.js ===
class Chatbot {
    constructor(chatBox, userInput, sendBtn, saveBtn) {
        this.chatBox = document.querySelector(chatBox);
        this.userInput = document.getElementById(userInput);
        this.sendBtn = document.getElementById(sendBtn);
        this.saveBtn = document.getElementById(saveBtn);
        this.currentMessage = '';

        this.initialize();
    }

    // Initialize event listeners
    initialize() {
        this.sendBtn.addEventListener('click', () => this.sendMessage());
        this.saveBtn.addEventListener('click', () => this.saveEditedResponse());
    }

    // Append a message to the chat box
    appendMessage(sender, message) {
        this.chatBox.innerHTML += `<div><strong>${sender}:</strong> ${message}</div>`;
        this.chatBox.scrollTop = this.chatBox.scrollHeight;
    }

    // Send message to the backend
    sendMessage() {
        const message = this.userInput.value.trim();
        if (!message) return;

        // Append user message
        this.appendMessage('You', message);
        this.userInput.value = '';

        fetch('http://127.0.0.1:5000/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ message }),
            credentials: 'same-origin'
        })
        .then(response => {
            if (!response.ok) {
                throw new Error('Network response was not ok');
            }
            return response.json();
        })
        .then(data => {
            const botResponse = data.response;

            // Append bot response with edit button
            this.appendMessage('Bot', `${botResponse} <button class="btn btn-sm btn-link edit-btn">Edit</button>`);

            // Add event listener for edit buttons
            document.querySelectorAll('.edit-btn').forEach(btn => {
                btn.addEventListener('click', () => {
                    this.currentMessage = message;
                    document.getElementById('edit-response').value = botResponse;
                    new bootstrap.Modal(document.getElementById('editModal')).show();
                });
            });

            this.chatBox.scrollTop = this.chatBox.scrollHeight;
        })
        .catch(error => console.error('Error:', error));
    }

    // Save edited response to data.json
    saveEditedResponse() {
        const updatedResponse = document.getElementById('edit-response').value.trim();
        if (!updatedResponse) return;

        fetch('http://127.0.0.1:5000/update', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ message: this.currentMessage, response: updatedResponse }),
            credentials: 'same-origin'
        })
        .then(response => response.json())
        .then(data => {
            alert(data.message);

            // Update the chat box with the new response
            this.appendMessage('Updated Bot', updatedResponse);

            this.chatBox.scrollTop = this.chatBox.scrollHeight;
        })
        .catch(error => console.error('Error:', error));
    }
}

// Init the Chatbot class
document.addEventListener('DOMContentLoaded', () => {
    new Chatbot('.chat-box', 'user-input', 'send-btn', 'save-btn');
});

=== File: openai-py/main.py ===
import os

# Set proxy environment variables
#os.environ['http_proxy'] = 'http://127.0.0.1:3128'
#os.environ['https_proxy'] = 'http://127.0.0.1:3128'

from flask import Flask, request, jsonify
from flask_cors import CORS
import json
import openai
from dotenv import load_dotenv

load_dotenv() # Load environment variables from .env file load_dotenv()

app = Flask(__name__)

# Allow all CORS
CORS(app, resources={r"/*": {"origins": "http://127.0.0.1:5500"}})

openai.api_key = os.getenv("OPENAI_API_KEY")

# Initial data.json
try:
    with open("data.json", "r") as f:
        data = json.load(f)
except FileNotFoundError:
    data = {"data": []}

# Helper function to save data to data.json
def save_data():
    with open("data.json", "w") as f:
        json.dump(data, f, indent=4)

# Endpoint to handle chatbot responses
@app.route("/chat", methods=["POST"])
def chat():
    if not request.is_json:
        return jsonify({"error": "Unsupported Media Type"}), 415

    user_input = request.json.get("message")
    if not user_input:
        return jsonify({"error": "Message not provided"}), 400

    for entry in data["data"]:
        if entry["question"] == user_input:
            return jsonify({"response": entry["answer"]})
    
    # Call OpenAI API if response is not found
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": user_input}]
    )
    answer = response.choices[0].message.content
    
    # Save the response in data.json
    data["data"].append({"question": user_input, "answer": answer})
    save_data()
    
    return jsonify({"response": answer})

# Endpoint to update bot responses
@app.route("/update", methods=["POST"])
def update():
    if not request.is_json:
        return jsonify({"error": "Unsupported Media Type"}), 415

    user_input = request.json.get("message")
    updated_response = request.json.get("response")
    if not user_input or not updated_response:
        return jsonify({"error": "Message or response not provided"}), 400

    for entry in data["data"]:
        if entry["question"] == user_input:
            entry["answer"] = updated_response
            save_data()
            return jsonify({"message": "Response updated successfully"})
    
    data["data"].append({"question": user_input, "answer": updated_response})
    save_data()
    
    return jsonify({"message": "Response updated successfully"})

if __name__ == "__main__":
    app.run(debug=True)